- abstract: With the abundance of natural language processing (NLP) frameworks and
    toolkits being used in the clinical arena, a new challenge has arisen - how do
    technologists collaborate across several projects in an easy way? Private sector
    companies are usually not willing to share their work due to intellectual property
    rights and profit-bearing decisions. Therefore, the annotation schemes and toolkits
    that they use are rarely shared with the wider community. We present the clinical
    language pipeline toolkit (CLPT) and its corresponding annotation scheme called
    the CLAO (Clinical Language Annotation Object) with the aim of creating a way
    to share research results and other efforts through a software solution. The CLAO
    is a unified annotation scheme for clinical technology processing (CTP) projects
    that forms part of the CLPT and is more reliable than previous standards such
    as UIMA, BioC, and cTakes for annotation searches, insertions, and deletions.
    Additionally, it offers a standardized object that can be exchanged through an
    API that the authors release publicly for CTP project inclusion.
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - emails: sakm1213@gmail.com
    first_name: Saranya
    google_scholar_id: https://scholar.google.com/citations?user=AkBGeBUAAAAJ&hl=en
    last_name: Krishnamoorthy
    name: Saranya Krishnamoorthy
    username: ~Saranya_Krishnamoorthy1
  - emails: yanyi.jiang@evicore.com
    first_name: Yanyi
    last_name: Jiang
    name: Yanyi Jiang
    username: ~Yanyi_Jiang1
  - emails: william.buchanan@evicore.com
    first_name: William
    last_name: Buchanan
    name: William Buchanan
    username: ~William_Buchanan1
  - emails: singh.ay@northeastern.edu
    first_name: Ayush
    last_name: Singh
    name: Ayush Singh
    orcid: https://orcid.org/0000-0002-3795-5623
    username: ~Ayush_Singh1
  - dblp_id: https://dblp.org/pid/286/4665.html
    emails: johneortega@gmail.com
    first_name: John
    google_scholar_id: https://scholar.google.com/citations?user=qzKvohMAAAAJ&hl=en
    homepage: https://naturallang.com
    institution: Universidad de Santiago de Compostela, Columbia University and New
      York University
    last_name: Ortega
    middle_name: E.
    name: John E. Ortega
    semantic_scholar_id: https://www.semanticscholar.org/author/J.-Ortega/118344292
    username: ~John_E._Ortega1
  decision: Accept
  file: 1.pdf
  id: 1
  openreview_id: Ff4V8HYpNV
  pdf_file: c29701d5aa4d462f9f2581bad5678cd3bc902717.pdf
  title: 'CLPT: A Universal Annotation Scheme and Toolkit for Clinical Language Processing'
- abstract: 'Automatically classifying electronic health records (EHRs) into diagnostic
    codes has been challenging to the NLP community. State-of-the-art methods treated
    this problem as a multi-label classification problem and proposed various architectures
    to model this problem. However, these systems did not leverage the superb performance
    of pretrained language models, which achieved superb performance on natural language
    understanding tasks. Prior work has shown that pretrained language models underperformed
    on this task with the regular fine-tuning scheme. Therefore, this paper aims at
    analyzing the causes of the underperformance and developing a framework for automatic
    ICD coding with pretrained language models. We spotted three main issues through
    the experiments: 1) large label space, 2) long input sequences, and 3) domain
    mismatch between pretraining and fine-tuning. We propose PLM-ICD, a framework
    that tackles the challenges with various strategies. The experimental results
    show that our proposed framework can overcome the challenges and achieves state-of-the-art
    performance in terms of multiple metrics on the benchmark MIMIC data. Our source
    code is available at https://github.com/MiuLab/PLM-ICD.'
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - dblp_id: https://dblp.org/pid/43/1695
    emails: f07922069@csie.ntu.edu.tw
    first_name: Chao-Wei
    google_scholar_id: https://scholar.google.com/citations?user=nmsPLncAAAAJ&hl=zh-TW
    institution: National Taiwan University
    last_name: Huang
    name: Chao-Wei Huang
    orcid: https://orcid.org/0000-0002-0319-0570
    semantic_scholar_id: https://www.semanticscholar.org/author/Chao-Wei-Huang/47396497
    username: ~Chao-Wei_Huang1
  - dblp_id: https://dblp.org/pid/213/7183
    emails: d08922014@ntu.edu.tw
    first_name: Shang-Chi
    institution: National Taiwan University
    last_name: Tsai
    name: Shang-Chi Tsai
    semantic_scholar_id: https://www.semanticscholar.org/author/Shang-Chi-Tsai/35705791
    username: ~Shang-Chi_Tsai1
  - dblp_id: https://dblp.org/pid/04/9878
    emails: yvchen@csie.ntu.edu.tw
    first_name: Yun-Nung
    google_scholar_id: https://scholar.google.com.tw/citations?user=jQLg-_UAAAAJ&hl=zh-TW
    homepage: http://vivianchen.idv.tw
    institution: Department of Computer Science and Informational Engineering, National
      Taiwan University
    last_name: Chen
    name: Yun-Nung Chen
    username: ~Yun-Nung_Chen1
  decision: Accept
  file: 2.pdf
  id: 2
  openreview_id: WqHXyjaAatj
  pdf_file: 5b992526f076498e8c8465fc8bbd1e0fda8a84ea.pdf
  title: 'PLM-ICD: Automatic ICD Coding with Pretrained Language Models'
- abstract: "Acronym disambiguation (AD) is the process of identifying the correct\
    \ expansion of the acronyms in text. AD is crucial in natural language understanding\
    \ of scientific and medical documents due to the high prevalence of technical\
    \ acronyms and the possible expansions. Given that natural language is often ambiguous\
    \ with more than one meaning for words, identifying the correct expansion for\
    \ acronyms requires learning of effective representations for words, phrases,\
    \ acronyms, and abbreviations based on their context. In this paper, we proposed\
    \ an approach to leverage the triplet networks and triplet loss which learns better\
    \ representations of text through distance comparisons of embeddings. We tested\
    \ both the triplet network-based method and the modified triplet network-based\
    \ method with $m$ networks on the AD dataset from the SDU@AAAI-21 AD task, CASI\
    \ dataset, and MeDAL dataset. F scores of 87.31%, 70.67%, and 75.75% were achieved\
    \ by the $m$ network-based approach for SDU, CASI, and MeDAL datasets respectively\
    \ indicating that triplet network-based methods have comparable performance but\
    \ with only 12% of the number of parameters in the baseline method. \nThis effective\
    \ implementation is available at https://github.com/sandaruSen/m_networks under\
    \ the MIT license. "
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - dblp_id: https://dblp.org/pid/242/9041
    emails: sandaru.seneviratne@anu.edu.au
    first_name: Sandaru
    google_scholar_id: https://scholar.google.com/citations?user=LOHNhxMAAAAJ&hl=en
    institution: Australian National University
    last_name: Seneviratne
    name: Sandaru Seneviratne
    semantic_scholar_id: https://www.semanticscholar.org/author/Sandaru-Seneviratne/148135947
    username: ~Sandaru_Seneviratne1
  - emails: eleni.daskalaki@anu.edu.au
    first_name: Elena
    google_scholar_id: https://scholar.google.ch/citations?user=aF-Yq3sAAAAJ&hl=en
    institution: Australian National University
    last_name: Daskalaki
    name: Elena Daskalaki
    orcid: https://orcid.org/0000-0002-7665-7039
    username: ~Elena_Daskalaki1
  - emails: artem.lenskiy@anu.edu.au
    first_name: Artem
    homepage: https://cecs.anu.edu.au/people/artem-lensky
    institution: Australian National University
    last_name: Lenskiy
    name: Artem Lenskiy
    username: ~Artem_Lenskiy1
  - dblp_id: https://dblp.org/pers/s/Suominen:Hanna.html
    emails: hanna.suominen@anu.edu.au
    first_name: Hanna
    google_scholar_id: https://scholar.google.com/citations?user=o4qymo4AAAAJ&hl=en
    homepage: https://cecs.anu.edu.au/people/hanna-suominen
    institution: Australian National University
    last_name: Suominen
    name: Hanna Suominen
    orcid: https://orcid.org/0000-0002-4195-1641
    username: ~Hanna_Suominen2
  decision: Accept
  file: 4.pdf
  id: 4
  openreview_id: lvopGS6DsVJ
  pdf_file: f9acb83eba329f007252b8ddeeb923fa9f2d06dd.pdf
  title: '$m$-Networks: Adapting the Triplet Networks for Acronym Disambiguation'
- abstract: 'Writing the conclusion section of radiology reports is essential for
    communicating the radiology findings and its assessment to physician in a condensed
    form. In this work, we employ a transformer-based Seq2Seq model for generating
    the conclusion section of German radiology reports. The model is initialized with
    the pretrained parameters of a German BERT model and fine-tuned in our downstream
    task on our domain data. We proposed two strategies to improve the factual correctness
    of the model. In the first method, next to the abstractive learning objective,
    we introduce an extraction learning objective to train the decoder in the model
    to both generate one summary sequence and extract the key findings from the source
    input. The second approach is to integrate the pointer mechanism into the transformer-based
    Seq2Seq model. The pointer network helps the Seq2Seq model to choose between generating
    tokens from the vocabulary or copying parts from the source input during generation.
    The results of the automatic and human evaluations show that the enhanced Seq2Seq
    model is capable of generating human-like radiology conclusions and that the improved
    models effectively reduce the factual errors in the generations despite the small
    amount of training data. '
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - emails: siting.liang@dfki.de
    first_name: Siting
    google_scholar_id: https://scholar.google.com/citations?user=NuNixssAAAAJ&hl=en
    homepage: https://www.dfki.de/web/ueber-uns/mitarbeiter/person/sili03
    institution: German Research Center for AI
    last_name: Liang
    name: Siting Liang
    username: ~Siting_Liang1
  - emails: klauskades@gmail.com
    first_name: Klaus
    last_name: Kades
    name: Klaus Kades
    username: ~Klaus_Kades1
  - emails: matthias.fink@uni-heidelberg.de
    first_name: Matthias
    last_name: Fink
    middle_name: A.
    name: Matthias A. Fink
    orcid: https://orcid.org/0000-0002-0189-7070
    username: ~Matthias_A._Fink1
  - emails: p.full@dkfz-heidelberg.de
    first_name: Peter
    institution: German Cancer Research Center (DKFZ)
    last_name: Full
    middle_name: Maximilian
    name: Peter Maximilian Full
    orcid: https://orcid.org/0000-0003-4326-8026
    username: ~Peter_Maximilian_Full1
  - emails: tim.weber@med.uni-heidelberg.de
    first_name: Tim
    homepage: https://www.klinikum.uni-heidelberg.de/personen/prof-dr-med-tim-weber-2548
    institution: "Ruprecht-Karls-Universit\xE4t Heidelberg"
    last_name: Weber
    middle_name: Frederik
    name: Tim Frederik Weber
    orcid: https://orcid.org/0000-0001-5911-123X
    username: ~Tim_Frederik_Weber1
  - emails: jens.kleesiek@uk-essen.de
    first_name: Jens
    google_scholar_id: https://scholar.google.com/citations?user=Vly6hRQAAAAJ
    institution: Institute for AI in Medicine (IKIM), University Medicine Essen
    last_name: Kleesiek
    name: Jens Kleesiek
    username: ~Jens_Kleesiek1
  - dblp_id: https://dblp.org/pid/s/MichaelStrube1
    emails: michael.strube@h-its.org
    first_name: Michael
    google_scholar_id: https://scholar.google.com/citations?user=s0_rS0kAAAAJ&hl=en
    homepage: https://www.h-its.org/people/prof-dr-michael-strube/
    institution: Heidelberg Institute for Theoretical Studies
    last_name: Strube
    name: Michael Strube
    username: ~Michael_Strube1
  - dblp_id: https://dblp.uni-trier.de/pers/hd/m/Maier=Hein:Klaus_H=
    emails: k.maier-hein@dkfz.de
    first_name: Klaus
    google_scholar_id: https://scholar.google.com/citations?user=oCrBpVMAAAAJ
    homepage: http://www.dkfz.de/en/mic
    institution: German Cancer Research Center and German Cancer Research Center
    last_name: Maier-Hein
    name: Klaus Maier-Hein
    orcid: https://orcid.org/0000-0002-6626-2463/print
    username: ~Klaus_Maier-Hein1
  decision: Accept
  file: 5.pdf
  id: 5
  openreview_id: fwx3HXkMyL8
  pdf_file: 9162532c3ea3ce6a0270c8011b5eb2d4dfedf677.pdf
  title: Fine-tuning BERT Models for Summarizing German Radiology Findings
- abstract: "Radiology report is an official record of radiologists' interpretation\
    \ of patients' radiographs and it\u2019s a crucial component in the overall medical\
    \ diagnostic process. However, it can contain various types of errors that can\
    \ lead to inadequate treatment or delay in diagnosis. To address this problem,\
    \ we propose a deep learning framework to detect errors in radiology reports.\
    \ Specifically, our method detects errors between findings and conclusion of chest\
    \ X-ray reports based on a supervised learning framework. To compensate for the\
    \ lack of data availability of radiology reports with errors, we develop an error\
    \ generator to systematically create artificial errors in existing reports. In\
    \ addition, we introduce a Medical Knowledge-enhancing Pre-training to further\
    \ utilize the knowledge of abbreviations and key phrases frequently used in the\
    \ medical domain. We believe that this is the first work to propose a deep learning\
    \ framework for detecting errors in radiology reports based on a rich contextual\
    \ and medical understanding. Validation on our radiologist-synthesized dataset,\
    \ based on MIMIC-CXR, shows 0.80 and 0.95 of the area under precision-recall curve\
    \ (AUPRC) and the area under the ROC curve (AUROC) respectively, indicating that\
    \ our framework can effectively detect errors in the real-world radiology reports."
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - emails: reonaledo@gmail.com
    first_name: Dabin
    homepage: https://github.com/reonaledo
    last_name: Min
    name: Dabin Min
    username: ~Dabin_Min1
  - emails: k223kim@uwaterloo.ca
    first_name: Kaeun
    google_scholar_id: https://scholar.google.com/citations?user=ZSi-gukAAAAJ&hl=en
    homepage: https://github.com/k223kim
    last_name: Kim
    name: Kaeun Kim
    username: ~Kaeun_Kim1
  - emails: lee87jh@gmail.com
    first_name: Jong Hyuk
    homepage: http://www.snuh.org/intro.do
    last_name: Lee
    name: Jong Hyuk Lee
    username: ~Jong_Hyuk_Lee1
  - emails: yisakk@snu.ac.kr
    first_name: Yisak
    last_name: Kim
    name: Yisak Kim
    orcid: https://orcid.org/0000-0002-5420-1436
    username: ~Yisak_Kim1
  - emails: cmpark.morphius@gmail.com
    first_name: Chang Min
    google_scholar_id: https://scholar.google.com/citations?user=ACimkrMAAAAJ&hl=en&oi=sra
    last_name: Park
    name: Chang Min Park
    orcid: https://orcid.org/my-orcid?orcid=0000-0003-1884-3738
    username: ~Chang_Min_Park1
  decision: Accept
  file: 6.pdf
  id: 6
  openreview_id: RQSLE_oFbNy
  pdf_file: fa6c1db74388b0996bc520bf477ea3b0d9655afc.pdf
  title: 'RRED : A Radiology Report Error Detector based on Deep Learning Framework '
- abstract: "In this work, cross-linguistic span prediction based on contextualized\
    \ word embedding models is used together with neural machine translation (NMT)\
    \ to transfer and apply the state-of-the-art models in natural language processing\
    \ (NLP) to a low-resource language clinical corpus. Two directions are evaluated:\
    \ (a) English models can be applied to translated texts to subsequently transfer\
    \ the predicted annotations to the source language and (b) existing high-quality\
    \ annotations can be transferred beyond translation and then used to train NLP\
    \ models in the target language. Effectiveness and loss of transmission is evaluated\
    \ using the German Berlin-T\xFCbingen-Oncology Corpus (BRONCO) dataset with transferred\
    \ external data from NCBI disease, SemEval-2013 drug-drug interaction (DDI) and\
    \ i2b2/VA 2010 data. The use of English models for translated clinical texts has\
    \ always involved attempts to take full advantage of the benefits associated with\
    \ them (large pre-trained biomedical word embeddings). To improve advances in\
    \ this area, we provide a general-purpose pipeline to transfer any annotated BRAT\
    \ or CoNLL format to various target languages. For the entity class medication,\
    \ good results were obtained with $0.806$ $F1$-score after re-alignment. Limited\
    \ success occurred in the diagnosis and treatment class with results just below\
    \ $0.5$ $F1$-score due to differences in annotation guidelines."
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - emails: henning.schaefer@uk-essen.de
    first_name: Henning
    institution: Institute for Transfusion Medicine, University Hospital Essen
    last_name: "Sch\xE4fer"
    name: "Henning Sch\xE4fer"
    orcid: https://orcid.org/0000-0002-4123-0406
    username: "~Henning_Sch\xE4fer1"
  - emails: ahmad.idrissi-yaghir@fh-dortmund.de
    first_name: Ahmad
    institution: Fachhochschule Dortmund
    last_name: Idrissi-Yaghir
    name: Ahmad Idrissi-Yaghir
    orcid: https://orcid.org/0000-0003-1507-9690
    username: ~Ahmad_Idrissi-Yaghir1
  - emails: henning.schaefer024@stud.fh-dortmund.de
    first_name: Peter
    homepage: https://www.uk-essen.de/transfusionsmedizin/direktor-und-sekretariate/
    institution: Institute for Transfusion Medicine, University Hospital Essen
    last_name: Horn
    middle_name: A.
    name: Peter A. Horn
    username: ~Peter_A._Horn1
  - dblp_id: https://dblp.org/pid/38/2820
    emails: christoph.friedrich@fh-dortmund.de
    first_name: Christoph
    google_scholar_id: https://scholar.google.de/citations?user=cBJs78QAAAAJ&hl=de
    homepage: https://www.fh-dortmund.de/friedrich/
    institution: Fachhochschule Dortmund
    last_name: Friedrich
    middle_name: M.
    name: Christoph M. Friedrich
    orcid: https://orcid.org/0000-0001-7906-0038
    username: ~Christoph_M._Friedrich1
  decision: Accept
  file: 7.pdf
  id: 7
  openreview_id: d2UL9rWGyd
  pdf_file: 310c8829696d16e9ee50b8df1d025fa01650c75a.pdf
  title: 'Cross-Language Transfer of High-Quality Annotations: Combining Neural Machine
    Translation with Cross-Linguistic Span Alignment to Apply NER to Clinical Texts
    in a Low-Resource Language'
- abstract: "Decision support systems based on clinical notes have the potential to\
    \ improve patient care by pointing doctors towards overseen risks. Predicting\
    \ a patient\u2019s outcome is an essential part of such systems, for which the\
    \ use of deep neural networks has shown promising results. However, the patterns\
    \ learned by these networks are mostly opaque and previous work revealed both\
    \ reproduction of systemic biases and unexpected behavior for out-of-distribution\
    \ patients. For application in clinical practice it is crucial to be aware of\
    \ such behavior. We thus introduce a testing framework that evaluates clinical\
    \ models regarding certain changes in the input. The framework helps to understand\
    \ learned patterns and their influence on model decisions. In this work, we apply\
    \ it to analyse the change in behavior with regard to the patient characteristics\
    \ gender, age and ethnicity. Our evaluation of three current clinical NLP models\
    \ demonstrates the concrete effects of these characteristics on the models\u2019\
    \ decisions. They show that model behavior varies drastically even when fine-tuned\
    \ on the same data with similar AUROC score. These results exemplify the need\
    \ for a broader communication of model behavior in the clinical domain."
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - emails: bettyvanaken@gmail.com
    first_name: Betty
    google_scholar_id: https://scholar.google.de/citations?user=3V75H5QAAAAJ
    homepage: https://prof.bht-berlin.de/loeser/people/betty-van-aken/
    last_name: Van Aken
    name: Betty van Aken
    username: ~Betty_van_Aken1
  - emails: sebastianhe93@gmail.com
    first_name: Sebastian
    last_name: Herrmann
    name: Sebastian Herrmann
    username: ~Sebastian_Herrmann1
  - dblp_id: https://dblp.uni-trier.de/pid/36/979.html
    emails: aloeser@bht-berlin.de
    first_name: Alexander
    google_scholar_id: https://scholar.google.de/citations?user=am2ohp0AAAAJ&hl=de
    homepage: http://www.datexis.com
    institution: Berlin University of Applied Sciences
    last_name: "L\xF6ser"
    name: "Alexander L\xF6ser"
    username: "~Alexander_L\xF6ser2"
  decision: Accept
  file: 9.pdf
  id: 9
  openreview_id: hPMqwKU5F75
  pdf_file: c1f04a509021cffccfdfcaa16b00dde77c7d2271.pdf
  title: What Do You See in this Patient? Behavioral Testing of Clinical NLP Models
- abstract: 'Existing question answering (QA) datasets derived from electronic health
    records (EHR) are artificially generated and consequently fail to capture realistic
    physician information needs. We present Discharge Summary Clinical Questions (DiSCQ),
    a newly curated question dataset composed of 2,000+ questions paired with the
    snippets of text (triggers) that prompted each question. The questions are generated
    by medical experts from 100+ MIMIC-III discharge summaries. We analyze this dataset
    to characterize the types of information sought by medical experts. We also train
    baseline models for trigger detection and question generation (QG), paired with
    unsupervised answer retrieval over EHRs. Our baseline model is able to generate
    high quality questions in over 62% of cases when prompted with human selected
    triggers. We release this dataset (and all code to reproduce baseline model results)
    to facilitate further research into realistic clinical QA and QG: https://github.com/elehman16/discq.'
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - dblp_id: https://dblp.org/pid/l/EricLehman
    emails: lehmer16@mit.edu
    first_name: Eric
    institution: Computer Science and Artificial Intelligence Laboratory, Electrical
      Engineering & Computer Science
    last_name: Lehman
    name: Eric Lehman
    username: ~Eric_Lehman1
  - emails: vladislav\_lialin@student.uml.edu
    first_name: Vladislav
    google_scholar_id: https://scholar.google.com/citations?user=B1Ijov0AAAAJ&hl=en
    homepage: https://scholar.google.com/citations?user=B1Ijov0AAAAJ&hl=en
    institution: University of Massachusetts, Lowell
    last_name: Lialin
    name: Vladislav Lialin
    username: ~Vladislav_Lialin1
  - emails: kylegaspi@up.edu.ph
    first_name: Katelyn Edelwina
    last_name: Legaspi
    middle_name: Yap
    name: Katelyn Edelwina Yap Legaspi
    username: ~Katelyn_Edelwina_Yap_Legaspi1
  - emails: annejanellesy@gmail.com
    first_name: Anne Janelle
    last_name: Sy
    middle_name: R.
    name: Anne Janelle R. Sy
    username: ~Anne_Janelle_R._Sy1
  - emails: patriciaspile@gmail.com
    first_name: Patricia Therese
    last_name: Pile
    middle_name: S.
    name: Patricia Therese S. Pile
    username: ~Patricia_Therese_S._Pile1
  - emails: nrialberto@gmail.com
    first_name: Nicole Rose
    last_name: Alberto
    name: Nicole Rose Alberto
    orcid: https://orcid.org/0000-0001-9166-8134
    username: ~Nicole_Rose_Alberto1
  - emails: rrragasa@up.edu.ph
    first_name: Richard Raymund
    last_name: Ragasa
    middle_name: Reyes
    name: Richard Raymund Reyes Ragasa
    username: ~Richard_Raymund_Reyes_Ragasa1
  - emails: ccmartinez4@up.edu.ph
    first_name: Corinna Victoria
    last_name: Puyat
    middle_name: M.
    name: Corinna Victoria M. Puyat
    orcid: https://orcid.org/0000-0002-5519-6501
    username: ~Corinna_Victoria_M._Puyat1
  - emails: mariannetalino@gmail.com
    first_name: Marianne Katharina
    last_name: "Tali\xF1o"
    middle_name: Vicera
    name: "Marianne Katharina Vicera Tali\xF1o"
    username: "~Marianne_Katharina_Vicera_Tali\xF1o1"
  - emails: isabellealberto3@gmail.com
    first_name: Isabelle Rose
    last_name: Alberto
    middle_name: I
    name: Isabelle Rose I Alberto
    orcid: https://orcid.org/my-orcid?orcid=0000-0002-7206-4770
    username: ~Isabelle_Rose_I_Alberto1
  - emails: pialfonso@up.edu.ph
    first_name: Pia Gabrielle
    institution: University of the Philippines
    last_name: Alfonso
    middle_name: Isidro
    name: Pia Gabrielle Isidro Alfonso
    orcid: https://orcid.org/0000-0002-0513-1355
    username: ~Pia_Gabrielle_Isidro_Alfonso1
  - emails: danamouk@buffalo.edu
    first_name: Dana
    homepage: https://github.com/danamouk
    last_name: Moukheiber
    name: Dana Moukheiber
    username: ~Dana_Moukheiber1
  - dblp_id: https://dblp.org/pid/00/8247
    emails: byron@ccs.neu.edu
    first_name: Byron
    google_scholar_id: https://scholar.google.com/citations?user=KTzRHmwAAAAJ&hl=en
    homepage: http://www.byronwallace.com/
    institution: Northeastern University
    last_name: Wallace
    middle_name: C
    name: Byron C Wallace
    username: ~Byron_C_Wallace1
  - dblp_id: https://dblp.org/pid/63/873
    emails: arum@cs.uml.edu
    first_name: Anna
    google_scholar_id: https://scholar.google.com.tw/citations?user=_Q1uzVYAAAAJ
    homepage: https://www.uml.edu/Sciences/computer-science/faculty/Rumshisky-Anna.aspx
    institution: University of Massachusetts, Lowell
    last_name: Rumshisky
    name: Anna Rumshisky
    semantic_scholar_id: https://www.semanticscholar.org/author/Anna-Rumshisky/1681193
    username: ~Anna_Rumshisky1
  - dblp_id: https://dblp.org/pid/204/0429
    emails: jjliang@us.ibm.com
    first_name: Jennifer
    homepage: https://researcher.watson.ibm.com/researcher/view.php?person=us-jjliang
    institution: IBM TJ Watson Research Center
    last_name: Liang
    middle_name: J.
    name: Jennifer J. Liang
    orcid: https://orcid.org/0000-0002-5197-1590
    username: ~Jennifer_J._Liang1
  - dblp_id: https://dblp.org/pid/06/7159
    emails: preethi.raghavan@gmail.com
    first_name: Preethi
    google_scholar_id: https://scholar.google.com/citations?user=oPolPeMAAAAJ&hl=en
    institution: 'Fidelity '
    last_name: Raghavan
    name: Preethi Raghavan
    username: ~Preethi_Raghavan1
  - emails: lceli@mit.edu
    first_name: Leo Anthony
    google_scholar_id: https://scholar.google.com/citations?user=kssA7YwAAAAJ&hl=en
    institution: Massachusetts Institute of Technology and Beth Israel Deaconess Medical
      Center
    last_name: Celi
    name: Leo Anthony Celi
    orcid: https://orcid.org/0000-0001-6712-6626
    username: ~Leo_Anthony_Celi1
  - dblp_id: https://dblp.org/pid/11/6043
    emails: psz@mit.edu
    first_name: Peter
    google_scholar_id: https://scholar.google.com/citations?user=1LuGqFQAAAAJ&hl=en&oi=ao
    homepage: https://people.csail.mit.edu/psz/web/
    institution: Massachusetts Institute of Technology
    last_name: Szolovits
    name: Peter Szolovits
    orcid: https://orcid.org/0000-0001-8411-6403
    username: ~Peter_Szolovits1
  decision: Accept
  file: 11.pdf
  id: 11
  openreview_id: umbYWHCSZeC
  pdf_file: 2c3203bff00cf684b4e47cf55dedbc29ce4cbb28.pdf
  title: Learning to Ask Like a Physician
- abstract: Word embeddings have been widely used in Natural Language Processing (NLP)
    tasks. Although these representations can capture the semantic information of
    words, they cannot learn the sequence-level semantics. This problem can be handled
    using contextual word embeddings derived from pre-trained language models, which
    have contributed to significant improvements in several NLP tasks. Further improvements
    are achieved when pre-training these models on domain-specific corpora. In this
    paper, we introduce Clinical Flair, a domain-specific language model trained on
    Spanish clinical narratives. To validate the quality of the contextual representations
    retrieved from our model, we tested them on four named entity recognition datasets
    belonging to the clinical and biomedical domains. Our experiments confirm that
    incorporating domain-specific embeddings into classical sequence labeling architectures
    improves model performance dramatically compared to general-domain embeddings,
    demonstrating the importance of having these resources available.
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - dblp_id: https://dblp.org/pid/139/7393
    emails: matias.rojas.g@ug.uchile.cl
    first_name: "Mat\xEDas"
    google_scholar_id: https://scholar.google.com/citations?user=-hjCWPMAAAAJ
    last_name: Rojas
    name: "Mat\xEDas Rojas"
    semantic_scholar_id: https://www.semanticscholar.org/author/M.-Rojas/116116019
    username: "~Mat\xEDas_Rojas1"
  - dblp_id: https://dblp.org/pid/268/0573
    emails: jdunstan@uchile.cl
    first_name: Jocelyn
    google_scholar_id: https://scholar.google.co.uk/citations?user=geH4mS0AAAAJ&hl=en&oi=ao
    homepage: https://sites.google.com/view/jdunstan/home
    institution: Universidad de Chile
    last_name: Dunstan
    name: Jocelyn Dunstan
    orcid: https://orcid.org/0000-0001-6726-7242
    semantic_scholar_id: https://www.semanticscholar.org/author/Jocelyn-Dunstan/121936601?sort=pub-date
    username: ~Jocelyn_Dunstan1
  - emails: fabian.villena@uchile.cl
    first_name: "Fabi\xE1n"
    google_scholar_id: https://scholar.google.com/citations?user=P-5s0ugAAAAJ&hl=es
    homepage: http://fabianvillena.cl/
    institution: Universidad de Chile
    last_name: Villena
    name: "Fabi\xE1n Villena"
    username: "~Fabi\xE1n_Villena1"
  decision: Accept
  file: 12.pdf
  id: 12
  openreview_id: 0esdpw8xA9M
  pdf_file: 91ba84aac5fb5bc3a0aed8b7bf47e3b5b215666c.pdf
  title: 'Clinical Flair: A Pre-Trained Language Model for Spanish Clinical Natural
    Language Processing '
- abstract: 'Recent studies show that neural natural processing models for medical
    code prediction suffer from a label imbalance issue. This study aims to investigate
    further imbalance in a medical code prediction dataset in terms of demographic
    variables and analyse performance differences in demographic groups. We use sample-based
    metrics to correctly evaluate the performance in terms of the data subject. Also,
    a simple label distance metric is proposed to quantify the difference in the label
    distribution between a group and the entire data. Our analysis results reveal
    that the model performs differently towards different demographic groups: significant
    differences between age groups and between insurance types are observed. Interestingly,
    we found a weak positive correlation between the number of training data of the
    group and the performance of the group. However, a strong negative correlation
    between the label distance of the group and the performance of the group is observed.
    This result suggests that the model tends to perform poorly in the group whose
    label distribution is different from the global label distribution of the training
    data set. Further analysis of the model performance is required to identify the
    cause of these differences and to improve the model building.'
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - emails: heereen.shim@kuleuven.be
    first_name: Heereen
    google_scholar_id: https://scholar.google.com/citations?user=uBQVbQQAAAAJ&hl=en&inst=1273811514435761252&oi=ao
    homepage: https://www.kuleuven.be/wieiswie/en/person/00125491
    last_name: Shim
    name: Heereen Shim
    username: ~Heereen_Shim1
  - dblp_id: https://dblp.org/pid/75/5451
    emails: dietwig.lowet@philips.com
    first_name: Dietwig
    institution: Philips Research
    last_name: Lowet
    name: Dietwig Lowet
    username: ~Dietwig_Lowet1
  - emails: stijn.luca@ugent.be
    first_name: Stijn
    google_scholar_id: https://scholar.google.be/citations?user=cl465SoAAAAJ&hl=nl
    institution: Ghent University
    last_name: Luca
    name: Stijn Luca
    username: ~Stijn_Luca1
  - emails: bart.vanrumste@kuleuven.be
    first_name: Bart
    institution: KU Leuven
    last_name: Vanrumste
    name: Bart Vanrumste
    orcid: https://orcid.org/0000-0002-9409-935X
    username: ~Bart_Vanrumste1
  decision: Accept
  file: 13.pdf
  id: 13
  openreview_id: zQlwvaK67UZ
  pdf_file: 18b71f62650161bd3f0ee149a78fdd03b5131353.pdf
  title: 'An exploratory data analysis: the performance differences of a medical code
    prediction system on different demographic groups'
- abstract: In this paper, we investigate ensemble methods for fine-tuning transformer-based
    pretrained models for clinical natural language processing tasks, specifically
    temporal relation extraction from the clinical narrative. Our experimental results
    on the THYME data show that ensembling as a fine-tuning strategy can further boost
    model performance over single learners optimized for hyperparameters. Dynamic
    snapshot ensembling is particularly beneficial as it fine-tunes a wide array of
    parameters and results in a 2.8\% absolute improvement in F1 over the base single
    learner.
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - dblp_id: https://dblp.org/pid/48/6248-1.html
    emails: christa60.wang@gmail.com
    first_name: Lijing
    google_scholar_id: https://scholar.google.com/citations?user=P0xw_5IAAAAJ&hl=en
    homepage: https://christa60.github.io/index.html
    last_name: Wang
    name: Lijing Wang
    username: ~Lijing_Wang2
  - dblp_id: https://dblp.org/pid/117/6625
    emails: timothy.miller@childrens.harvard.edu
    first_name: Timothy
    google_scholar_id: https://scholar.google.com/citations?user=iKtu9fgAAAAJ&hl=en
    homepage: https://scholar.harvard.edu/tim-miller
    institution: Harvard University
    last_name: Miller
    middle_name: A
    name: Timothy A Miller
    semantic_scholar_id: https://www.semanticscholar.org/author/Timothy-Miller/144950569
    username: ~Timothy_A_Miller1
  - dblp_id: https://dblp.org/pid/52/5246
    emails: bethard@arizona.edu
    first_name: Steven
    google_scholar_id: https://scholar.google.com.tw/citations?user=sXM8J5EAAAAJ
    homepage: http://bethard.faculty.arizona.edu/
    institution: University of Arizona
    last_name: Bethard
    name: Steven Bethard
    orcid: https://orcid.org/0000-0001-9560-6491
    semantic_scholar_id: https://www.semanticscholar.org/author/Steven-Bethard/2105138
    username: ~Steven_Bethard1
  - emails: guerganasavova@hotmail.com
    first_name: Guergana
    google_scholar_id: https://scholar.google.com/citations?user=9538Cr4AAAAJ&hl=en&oi=sra
    institution: Harvard University
    last_name: Savova
    middle_name: K
    name: Guergana K Savova
    orcid: https://orcid.org/0000-0002-5887-200X
    username: ~Guergana_K_Savova1
  decision: Accept
  file: 14.pdf
  id: 14
  openreview_id: aE9AmHRr2I
  pdf_file: 1161d81e1fa60eaea1355cc316ce50de6e20b8aa.pdf
  title: Ensemble-based Fine-Tuning Strategy for Temporal Relation Extraction from
    the Clinical Narrative
- abstract: Sequence-to-sequence models are appealing because they allow both encoder
    and decoder to be shared across many tasks by formulating those tasks as text-to-text
    problems. Despite recently reported successes of such models, we find that engineering
    input/output representations for such text-to-text models is challenging. On the
    Clinical TempEval 2016 relation extraction task, the most natural choice of output
    representations, where relations are spelled out in simple predicate logic statements,
    did not lead to good performance. We explore a variety of input/output representations,
    with the most successful prompting one event at a time, and achieving results
    competitive with standard pairwise temporal relation extraction systems.
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: null
  authors:
  - dblp_id: https://dblp.org/pid/83/3441
    emails: ddligach@luc.edu
    first_name: Dmitriy
    google_scholar_id: https://scholar.google.com/citations?hl=en&user=mkLwEPkAAAAJ&view_op=list_works&sortby=pubdate
    homepage: https://www.dmitriydligach.com
    institution: Loyola University Chicago
    last_name: Dligach
    name: Dmitriy Dligach
    semantic_scholar_id: https://www.semanticscholar.org/author/1839381
    username: ~Dmitriy_Dligach1
  - dblp_id: https://dblp.org/pid/52/5246
    emails: bethard@arizona.edu
    first_name: Steven
    google_scholar_id: https://scholar.google.com.tw/citations?user=sXM8J5EAAAAJ
    homepage: http://bethard.faculty.arizona.edu/
    institution: University of Arizona
    last_name: Bethard
    name: Steven Bethard
    orcid: https://orcid.org/0000-0001-9560-6491
    semantic_scholar_id: https://www.semanticscholar.org/author/Steven-Bethard/2105138
    username: ~Steven_Bethard1
  - dblp_id: https://dblp.org/pid/117/6625
    emails: timothy.miller@childrens.harvard.edu
    first_name: Timothy
    google_scholar_id: https://scholar.google.com/citations?user=iKtu9fgAAAAJ&hl=en
    homepage: https://scholar.harvard.edu/tim-miller
    institution: Harvard University
    last_name: Miller
    middle_name: A
    name: Timothy A Miller
    semantic_scholar_id: https://www.semanticscholar.org/author/Timothy-Miller/144950569
    username: ~Timothy_A_Miller1
  - emails: guerganasavova@hotmail.com
    first_name: Guergana
    google_scholar_id: https://scholar.google.com/citations?user=9538Cr4AAAAJ&hl=en&oi=sra
    institution: Harvard University
    last_name: Savova
    middle_name: K
    name: Guergana K Savova
    orcid: https://orcid.org/0000-0002-5887-200X
    username: ~Guergana_K_Savova1
  decision: Accept
  file: 16.pdf
  id: 16
  openreview_id: mB4jTlXMsSG
  pdf_file: 5f62901ee2a468b04907f4538d14280b1075eb9e.pdf
  title: Exploring Text Representations for Generative Temporal Relation Extraction